############################ MATLAB CLASSIFICATION LEARNER ###############################

# Primero, y tras hacer el Train para todos los modelos de forma automatica mediante Classifiaction Learner App, debemos exportar cómo una nueva función del workspace de MATLAB, aquel con una mayor accuracy. Cómo se explica en el report, el modelo con una mayor accuracy ha resultado ser para Bagged_Trees, y la función para este modelo se exporta cómo "trainedModel_Bagged_Trees". Si creamos el código para este modelo se genera:



# A continuación, cargamos el datasaet perteneciente a la información mutacional de los 84 genes seleccionados para las 17 muestras de los HGBCL, NOS. Este, toma el nombre de HGMLTEST. Así, para hacer nuevas predicciones para esta variable, utilizando el modelo exportado:
 
>> yfit = trainedModel_1.predictFcn(HGMLTEST) 

# El output que se nos devuelve, es una lista de 0 y 1, en el orden de las muestras de HGMLTEST, el cual nos dice si la variable se ha predicho cómo 1 (BL) o 2 (DLBCL). 

ans =

     1
     0
     0
     1
     1
     0
     1
     1
     0
     1
     1
     0
     1
     0
     1
     0
     0

# Cómo podemos comprobar, esta información coincide con la del status de MYC. Es decir aquellas muestras con MYC-positivo, se han predicho cómo BL mientras que las de MYC-negativo, cómo DLBCL.

# A continuación, debemos calcular, qué importancia tiene cada feature, es decir, cada uno de los 84 genes, para esta predicción:

>> Importance = oobPermutedPredictorImportance(trainedModel_Bagged_Trees.ClassificationEnsemble) # Es muy importante, que cuando exportamos el modelo, miremos de qué tipo de clasificador se trata. Así, debemos indicat que pertenece a 'Classification Ensemble').


# El output que se nos devuelve es un vector de valores para cada uno de los predictores. Así,  out-of-bag, predictor importance estimates by permutation using the random forest of regression trees Mdl. Mdl must be a Bagged Ensemble model object (https://es.mathworks.com/help/stats/regressionbaggedensemble.oobpermutedpredictorimportance.html).  

  Columns 1 through 18
    0.1857         0         0   -0.0448         0    0.3749         0    0.3855         0         0         0         0         0         0         0         0   -0.1857    0.0671
  Columns 19 through 36

         0         0    0.1857         0         0   -0.1857    0.5154   -0.3328         0         0         0         0         0         0         0   -0.0296    0.2392         0

  Columns 37 through 54

    0.5769   -0.1857   -0.1857    1.2392         0         0         0         0    0.3156         0         0         0    1.4568         0         0         0         0    0.2552

  Columns 55 through 72

    0.4136         0         0    0.1857         0    0.3880         0         0         0         0         0         0    0.9575    0.6066         0         0    0.1857    0.1857

  Columns 73 through 84

         0         0   -0.0547         0         0    0.3035    0.1857         0    0.6891         0         0         0

# Aún así, cómo este procedimiento ha sido elaborado de forma automatica, tansolo para provar todos los tipos de modelos de clasificación y escoger el óptimo para nuestros datos, procedemos a elaborar nosotros mismos el modelo en el workspace. Antes y para hacerlo bien, debemos mirar qué numero de trees ha escogido el Classification learner anteriormente. Así, escogemos 30, cómo número optimo de trees. 

>> Mdl = TreeBagge(30, FINALMLTABLEWITHOUTMYCREARRANGEMENT1, "Diagnosis", 'PredictorSelection', 'curvature', 'OOBPredictorImportance','on')

Mdl = 

TreeBagger
Ensemble with 30 bagged decision trees:
                     Training X:             [104x85]
                     Training Y:              [104x1]
                     Method:       classification
                     NumPredictors:                   85
                     NumPredictorsToSample:                   10
                     MinLeafSize:                    1
                    InBagFraction:                    1
                    SampleWithReplacement:                    1
                    ComputeOOBPrediction:                    0
                    ComputeOOBPredictorImportance:                    0
                    Proximity:                   []
                    ClassNames:             '0'             '1'

# A continuación, y cambiando el {1} por números del 1 al 30 (número de trees utilizados), podemos ver los decission trees que ha utilizado el modelo. Esto, también nos dará infomación de qué predictores sirven para la predicción cómo BL o cómo DLBCL. 

>> view(Mdl.Trees{1},'Mode','graph')

# Para el siguiente paso, volvemos a permutar la importancia de los predictores para la clasificación, pero en este caso, a través de la función TreeBagger, establecido en el workspace. Por tanto, procedemos a realizad un barplot para sus valores. Es muy importante que pare realizarlo, hayamos puesto los argumentos 'OOBPredictorImportance','on', cuando hemos definido la función.

>> imp = Mdl.OOBPermutedPredictorDeltaError;
figure;
bar(imp);
title('Curvature Test');
ylabel('Predictor importance estimates');
xlabel('Predictors');
h = gca;
h.XTickLabel = Mdl.PredictorNames;
h.XTickLabelRotation = 45;
h.TickLabelInterpreter = 'none';

# A continuación, podemos volver a establecer la predicción sobre el dataset HGMLTEST:
>> Yfit = predict(Mdl,HGMLTEST)
Yfit =

  17×1 cell array

    {'1'}
    {'0'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'0'}

# Una vez hemos definido la importancia de cada uno de los predictores o features en la predicción, también es interesante resaltar con qué likelihood se ha predicho cada una de las samples. Es decir, con qué computed score se predice cada uno de los casos, además, también podemos saber su desviación estandard.

>> [Yfit,scores,stdevs] = predict(Mdl, HGMLTEST)
Yfit =

  17×1 cell array

    {'1'}
    {'0'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'0'}


scores =

    0.2528    0.7472
    0.9126    0.0874
    0.7360    0.2640
    0.0530    0.9470
    0.0477    0.9523
    0.7244    0.2756
    0.4167    0.5833
    0.1833    0.8167
    0.6525    0.3475
    0.1894    0.8106
    0.1828    0.8172
    0.9610    0.0390
    0.4073    0.5927
    0.9711    0.0289
    0.1354    0.8646
    0.7050    0.2950
    0.7292    0.2708


stdevs =

    0.4186    0.4186
    0.2517    0.2517
    0.3948    0.3948
    0.1997    0.1997
    0.1850    0.1850
    0.3646    0.3646
    0.4845    0.4845
    0.3760    0.3760
    0.3558    0.3558
    0.3745    0.3745
    0.3612    0.3612
    0.0743    0.0743
    0.4610    0.4610
    0.0485    0.0485
    0.3170    0.3170
    0.4401    0.4401
    0.3363    0.3363

# Importance 

>> imp = Mdl.OOBPermutedPredictorDeltaError;
figure;
bar(imp);
title('Curvature Test');
ylabel('Predictor importance estimates');
xlabel('Predictors');
h = gca;
h.XTickLabel = Mdl.PredictorNames;
h.XTickLabelRotation = 45;
h.TickLabelInterpreter = 'none';

imp =

  Columns 1 through 18

         0         0   -0.1857    0.0646         0    0.3332         0   -0.1159         0         0         0         0         0    0.1857         0         0         0   -0.1686

  Columns 19 through 36

         0         0         0         0         0   -0.1857    0.3589   -0.1857         0         0         0         0         0         0         0         0   -0.0464         0

  Columns 37 through 54

    0.0605         0   -0.1857    1.9942         0         0         0    0.1857    0.1893         0         0         0    0.8499    0.1857         0    0.1857         0    0.1205

  Columns 55 through 72

    0.5000         0         0    0.1857         0         0         0         0         0         0         0         0    0.8254    0.4107         0         0         0         0

  Columns 73 through 84

    0.3131         0    0.5444         0         0    0.3140    0.2473         0    0.7658         0    0.0000         0


# 

>> figure;
oobErrorBaggedEnsemble = oobError(Mdl);
plot(oobErrorBaggedEnsemble)
xlabel 'Number of grown trees';
ylabel 'Out-of-bag classification error';


>> Mdl_IMP = TreeBagger(30,FINALMLTABLEWITHOUTMYCREARRANGEMENTIMPORTANT,"Diagnosis",'OOBPredictorImportance','on')
Error using classreg.learning.internal.table2FitMatrix>resolveName (line 284)
One or more 'ResponseName' parameter values are invalid.

Error in classreg.learning.internal.table2FitMatrix (line 86)
        ResponseName = resolveName('ResponseName',ResponseName,FormulaResponseName,false,VarNames);

Error in ClassificationTree.prepareData (line 652)
            [X,Y,vrange,wastable,varargin] = classreg.learning.internal.table2FitMatrix(X,Y,varargin{:},'OrdinalIsCategorical',false);

Error in TreeBagger/init (line 1341)
                    ClassificationTree.prepareData(x,y,...

Error in TreeBagger (line 619)
            bagger = init(bagger,X,Y,makeArgs{:});
 
>> Mdl_IMP = TreeBagger(30,FINALMLTABLEWITHOUTMYCREARRANGEMENTIMPORTANT1,"Diagnosis",'OOBPredictorImportance','on')

Mdl_IMP = 

  TreeBagger
Ensemble with 30 bagged decision trees:
                    Training X:             [104x21]
                    Training Y:              [104x1]
                        Method:       classification
                 NumPredictors:                   21
         NumPredictorsToSample:                    5
                   MinLeafSize:                    1
                 InBagFraction:                    1
         SampleWithReplacement:                    1
          ComputeOOBPrediction:                    1
 ComputeOOBPredictorImportance:                    1
                     Proximity:                   []
                    ClassNames:             '0'             '1'

  Properties, Methods

>> [Yfit,scores,stdevs] = predict(Mdl_IMP, HGMLTEST)

Yfit =

  17×1 cell array

    {'1'}
    {'0'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'0'}


scores =

    0.4875    0.5125
    0.9144    0.0856
    0.7315    0.2685
    0.0462    0.9538
         0    1.0000
    0.9144    0.0856
    0.2149    0.7851
    0.0714    0.9286
    0.9144    0.0856
    0.0048    0.9952
    0.2913    0.7087
    0.9144    0.0856
    0.2073    0.7927
    0.9144    0.0856
    0.0333    0.9667
    0.5091    0.4909
    0.9183    0.0817


stdevs =

    0.4521    0.4521
    0.0678    0.0678
    0.3627    0.3627
    0.1841    0.1841
         0         0
    0.0678    0.0678
    0.3950    0.3950
    0.2495    0.2495
    0.0678    0.0678
    0.0256    0.0256
    0.3881    0.3881
    0.0678    0.0678
    0.3645    0.3645
    0.0678    0.0678
    0.1795    0.1795
    0.4743    0.4743
    0.0692    0.0692

>> imp = Mdl_IMP.OOBPermutedPredictorDeltaError

imp =

  Columns 1 through 18

   -0.2670    0.1857         0    0.3297    0.1000    1.9764         0    0.2673    1.6127         0         0    0.4679    0.3608         0    0.5871    0.3916    0.2668    0.2280

  Columns 19 through 21

    0.2580         0    0.8751

>> imp = Mdl.OOBPermutedPredictorDeltaError

imp =

  Columns 1 through 18

         0         0   -0.1857    0.0646         0    0.3332         0   -0.1159         0         0         0         0         0    0.1857         0         0         0   -0.1686

  Columns 19 through 36

         0         0         0         0         0   -0.1857    0.3589   -0.1857         0         0         0         0         0         0         0         0   -0.0464         0

  Columns 37 through 54

    0.0605         0   -0.1857    1.9942         0         0         0    0.1857    0.1893         0         0         0    0.8499    0.1857         0    0.1857         0    0.1205

  Columns 55 through 72

    0.5000         0         0    0.1857         0         0         0         0         0         0         0         0    0.8254    0.4107         0         0         0         0

  Columns 73 through 84

    0.3131         0    0.5444         0         0    0.3140    0.2473         0    0.7658         0    0.0000         0

>> [Yfit,scores,stdevs] = predict(Mdl, HGMLTEST)

Yfit =

  17×1 cell array

    {'1'}
    {'0'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'0'}


scores =

    0.2528    0.7472
    0.9126    0.0874
    0.7360    0.2640
    0.0530    0.9470
    0.0477    0.9523
    0.7244    0.2756
    0.4167    0.5833
    0.1833    0.8167
    0.6525    0.3475
    0.1894    0.8106
    0.1828    0.8172
    0.9610    0.0390
    0.4073    0.5927
    0.9711    0.0289
    0.1354    0.8646
    0.7050    0.2950
    0.7292    0.2708


stdevs =

    0.4186    0.4186
    0.2517    0.2517
    0.3948    0.3948
    0.1997    0.1997
    0.1850    0.1850
    0.3646    0.3646
    0.4845    0.4845
    0.3760    0.3760
    0.3558    0.3558
    0.3745    0.3745
    0.3612    0.3612
    0.0743    0.0743
    0.4610    0.4610
    0.0485    0.0485
    0.3170    0.3170
    0.4401    0.4401
    0.3363    0.3363

>> view(Mdl.Trees{1},'Mode','graph')
>> view(Mdl.Trees{3},'Mode','graph')
>> view(Mdl.Trees{2},'Mode','graph')
>> view(Mdl.Trees{1},'Mode','graph')
>> view(Mdl.Trees{4},'Mode','graph')
>> [Yfit,scores,stdevs] = predict(Mdl_IMP, HGMLTEST)

Yfit =

  17×1 cell array

    {'1'}
    {'0'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'1'}
    {'0'}
    {'0'}


scores =

    0.4875    0.5125
    0.9144    0.0856
    0.7315    0.2685
    0.0462    0.9538
         0    1.0000
    0.9144    0.0856
    0.2149    0.7851
    0.0714    0.9286
    0.9144    0.0856
    0.0048    0.9952
    0.2913    0.7087
    0.9144    0.0856
    0.2073    0.7927
    0.9144    0.0856
    0.0333    0.9667
    0.5091    0.4909
    0.9183    0.0817


stdevs =

    0.4521    0.4521
    0.0678    0.0678
    0.3627    0.3627
    0.1841    0.1841
         0         0
    0.0678    0.0678
    0.3950    0.3950
    0.2495    0.2495
    0.0678    0.0678
    0.0256    0.0256
    0.3881    0.3881
    0.0678    0.0678
    0.3645    0.3645
    0.0678    0.0678
    0.1795    0.1795
    0.4743    0.4743
    0.0692    0.0692


